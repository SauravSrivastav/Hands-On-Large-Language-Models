{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDe7DsPWmEBV"
   },
   "source": [
    "<h1>🤖 AI Se Baatein: Language Models Ka Pehla Kadam 🤖</h1>\n",
    "<i>Samjho kaise computers hamari bhasha samajhte hain aur bolte hain!</i>\n",
    "\n",
    "---\n",
    "\n",
    "Namaste dosto! 👋 Taiyaar ho ek amazing journey par jaane ke liye? 🚀 Aaj hum seekhenge AI ki duniya ka ek super cool part - Language Models! Socho, jaise hum insaan ek doosre se baat karte hain, waise hi hum computer ko bhi sikhate hain baat karna! Yeh sab kaise hota hai? Chalo dekhte hain is notebook mein, bilkul simple aur fun tarike se, jaise koi dost samjha raha ho! 😊\n",
    "\n",
    "Yeh notebook humari guide banegi Chapter 1 ke liye.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] - Installing Packages\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "💡 **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "Iska matlab hai ki humein AI model ko chalaane ke liye ek powerful engine (GPU) chahiye taaki kaam tez ho. Google Colab mein hum yeh \"super engine\" free mein select kar sakte hain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install transformers>=4.40.1 accelerate>=0.27.2\n",
    "\n",
    "# Yeh code agar aap Google Colab par ho toh chalana padega.\n",
    "# Yeh kuch special software \"tools\" install karta hai AI ke liye.\n",
    "# Socho jaise naye toy ke liye battery ya special key chahiye hoti hai.\n",
    "# \"transformers\" aur \"accelerate\" in tools ke naam hain.\n",
    "# Agar is line ke aage '#' hai, toh usko hata dena chalane se pehle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXp09JFsFBXi"
   },
   "source": [
    "# Phi-3 Se Milo! 🤖\n",
    "\n",
    "Humara pehla step hai hamare AI dost (model) ko load karna. Aaj hum **Phi-3** naam ke model ko load karenge, jo Microsoft ne banaya hai aur instructions follow karne mein smart hai. \n",
    "\n",
    "AI model use karne ke liye humein do cheezein chahiye:\n",
    "\n",
    "1.  **The Model:** Yeh AI ka \"brain\" hai jo sochta hai. (Socho yeh tumhara AI dost khud hai).\n",
    "2.  **The Tokenizer:** Yeh ek \"translator\" hai jo hamari bhasha ko numbers mein badalta hai jo computer samajh sake, aur computer ke numbers ko wapas hamari bhasha mein. (Yeh AI dost ke kaan aur muh hain!).\n",
    "\n",
    "Hum in dono ko load karenge aur GPU par daal denge taaki processing tez ho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSNalRXZyTTk"
   },
   "outputs": [],
   "source": [
    "# transformers library se AI model aur tokenizer load karne ke tools laate hain.\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Ab hamara AI dost (model) load karte hain.\n",
    "# Uska naam \"microsoft/Phi-3-mini-4k-instruct\" hai, jaise toy ka naam hota hai.\n",
    "# device_map=\"cuda\" matlab isko tez GPU engine par chalao.\n",
    "# torch_dtype=\"auto\" aur trust_remote_code=False kuch settings hain jo isko theek se chalne mein help karti hain.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "# Ab AI dost ka translator (tokenizer) load karte hain.\n",
    "# Iska naam bhi model ke naam jaisa hi hai taaki sahi match ho.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# Ab hamara AI dost aur uska translator taiyaar hain! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yeh Code Kya Karta Hai? 🤔**\n",
    "\n",
    "Yeh code `transformers` library se hamara AI dost (model) aur uska translator (tokenizer) load karta hai. `AutoModelForCausalLM` AI model load karta hai aur `AutoTokenizer` uska tokenizer. Hum model ka naam (\"microsoft/Phi-3-mini-4k-instruct\") bataate hain, aur `device_map=\"cuda\"` use karke isko GPU par load karte hain taaki yeh tez kaam kare. Yeh steps zaroori hain taaki hamara AI dost taiyaar ho baat karne ke liye!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdyYYS0E5fEU"
   },
   "source": [
    "## Easy Mode On! (Pipeline Ka Jaadu) ✨\n",
    "\n",
    "Humne model aur tokenizer load kar liye hain, par unhein separately use karna thoda complex ho sakta hai. Socho jaise koi toy parts mein aaya ho. Usse khelne se pehle assemble karna padega na?\n",
    "\n",
    "Isliye, `transformers` library mein ek \"Easy Button\" hai jiska naam hai `pipeline`. Yeh model aur tokenizer ko ek saath assemble kar deta hai aur humare liye AI model ko use karna super simple bana deta hai! Jaise ek smart assistant ho jo saara mushkil kaam khud kar de."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DiUi4Wu1FCyN"
   },
   "outputs": [],
   "source": [
    "# transformers library se \"Easy Button\" banane ka tool laate hain.\n",
    "from transformers import pipeline\n",
    "\n",
    "# Ab hum woh \"Easy Button\" bana rahe hain.\n",
    "# Usko \"generator\" naam de rahe hain kyunki yeh text generate karega.\n",
    "# \"text-generation\" matlab iska kaam text banana hai.\n",
    "# model=model aur tokenizer=tokenizer se hum usko hamara AI brain aur translator de rahe hain.\n",
    "# return_full_text=False matlab humein sirf jawab chahiye, sawal dobara nahi.\n",
    "# max_new_tokens=500 matlab zyada se zyada itne words banana.\n",
    "# do_sample=False matlab sabse seedha aur likely answer dena.\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "# Hamara \"Easy Button\" ab taiyaar hai commands lene ke liye! 👍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yeh Code Kya Karta Hai? 🤔**\n",
    "\n",
    "Yeh code `pipeline` naam ka ek \"Easy Button\" bana raha hai. Hum usko bata rahe hain ki yeh pipeline \"text-generation\" (text banane) ke liye hai. Phir hum usko bataate hain ki konsa `model` aur `tokenizer` use karna hai (jo humne pichle step mein load kiye the). `return_full_text=False` ka matlab hai ki jab AI jawab dega, toh humein sirf uska jawab chahiye, hamara sawal dobara nahi. `max_new_tokens=500` matlab AI zyada se zyada 500 naye words (ya tokens) bana sakta hai. `do_sample=False` matlab AI sabse possible answer dega, randomly kuch naya try nahi karega (abhi predictability acchi hai!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD49kysT5mMY"
   },
   "source": [
    "## AI Dost Se Sawal Poochna Aur Jawab Sunna! 🗣️👂\n",
    "\n",
    "Ab jab hamara AI dost easy mode mein ready hai, time hai usse baat karne ka! Jab hum AI model ko kuch poochhte hain ya kuch karne ko bolte hain, usko **Prompt** kehte hain. Prompt ek tarah se hamara instruction hota hai AI ke liye.\n",
    "\n",
    "Phi-3 jaisa instruct model instructions ko follow karne mein accha hai. Instruction theek se samajh aaye, iske liye ek special format use hota hai jisko **chat format** kehte hain. Ismein hum bataate hain ki kaun bol raha hai - \"user\" (hum) ya \"assistant\" (AI model). Jaise message app mein hota hai!\n",
    "\n",
    "Aur phir hum dekhenge ki hamara AI dost kya amazing jawab deta hai!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hkR7LBmiyXmY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why did the chicken join the band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "# Yeh hamara message hai jo hum AI dost ko bhejna chahte hain.\n",
    "# Hum isko ek list mein rakhte hain, future mein hum aur messages bhi daal sakte hain baatચીત (chat) banane ke liye.\n",
    "# Har message ek {{'{}'}} bracket mein hai.\n",
    "messages = [\n",
    "    # Pehla message: Hum (user) bol rahe hain.\n",
    "    # content: hum kya bol rahe hain - \"Create a funny joke about chickens.\"\n",
    "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
    "]\n",
    "\n",
    "# Ab hum yeh message apne \"Easy Button\" (generator) ko dete hain.\n",
    "# generator is message ko padhega aur jawab banayega.\n",
    "# Jawab \"output\" naam ke box mein store ho jayega.\n",
    "output = generator(messages)\n",
    "\n",
    "# Ab hum \"output\" box ke andar dekhte hain aur jawab nikalte hain.\n",
    "# output ek list jaisa hai, isliye hum uska pehla item [0] lete hain.\n",
    "# Us item ke andar \"generated_text\" naam ka ek chhota box hai, usmein actual joke hai.\n",
    "# print() se hum us joke ko screen par dikhaate hain.\n",
    "print(output[0][\"generated_text\"])\n",
    "\n",
    "# Dekha? AI ne kitna mast joke sunaya! 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yeh Code Kya Karta Hai? 🤔**\n",
    "\n",
    "Pehle part (`messages = [...]`) mein hum apna sawal (prompt) taiyaar kar rahe hain. Yeh ek list hai jismein ek message hai. Message mein `role` \"user\" hai (yaani hum bol rahe hain) aur `content` woh text hai jo hum bol rahe hain - \"Create a funny joke about chickens.\" Hum AI se chicken par ek funny joke banane ko keh rahe hain!\n",
    "\n",
    "Doosre part mein (`output = generator(messages)` aur `print(...)`) hum yeh sawal apne `generator` pipeline ko dete hain. Pipeline magic karke joke generate karta hai aur use `output` variable mein store karta hai. Finally, `print(output[0][\"generated_text\"])` us generated joke ko screen par dikhata hai taaki hum use padh sakein. Mazaa aaya?! 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seekhe Hue Shabd (Glossary) 📚\n",
    "\n",
    "Chalo, jo naye aur thode technical shabd humne seekhe, unka matlab aur thoda simple explanation aur analogies dekh lete hain:\n",
    "\n",
    "*   **Language Model (LLM):** Yeh ek smart computer program hai jo bahut saari bhasha (text) padh kar seekhta hai aur phir naya text bana sakta hai, sawalon ke jawab de sakta hai, wagera. Jaise ek super padha likha insaan jo bahut saari books padh chuka ho aur ab kuch bhi likh ya bol sakta ho!\n",
    "*   **AI (Artificial Intelligence):** Computers ko insaano jaisa sochne aur seekhne ki ability dena. Language Models AI ka ek hissa hain.\n",
    "*   **GPU (Graphics Processing Unit):** Ek special computer chip jo ek saath bahut saari calculations kar sakti hai. AI models ko tez chalane ke liye yeh bahut zaroori hai. **Analogy:** Jaise ek racing car ka powerful engine ya ek superhero ki special power.\n",
    "*   **Colab (Google Colaboratory):** Google ka ek free online tool jahan hum code likh sakte hain aur run kar sakte hain, jismein GPU power bhi milti hai. **Analogy:** Jaise Google Drive jahan files online save hote hain, Colab jahan code online chalta hai.\n",
    "*   **Transformers:** Hugging Face naam ki company ka ek popular software library (packages ka collection) jo Language Models ko use karna easy bana deta hai. **Analogy:** Jaise ek bada toy store jahan alag alag tarah ke AI toys (models) aur unke parts milte hain.\n",
    "*   **Tokenizer:** Yeh tool jo text (words, sentences) ko numbers mein badalta hai computer ke samajhne ke liye, aur wapas numbers ko text mein. **Analogy:** Jaise ek translator jo bhasha badalta hai, par yeh words ko numbers aur numbers ko words mein badalta hai. AI model ke kaan aur muh.\n",
    "*   **Pipeline:** Transformers library ka ek tool jo AI model aur tokenizer ko ek saath jod deta hai aur use karna super simple bana deta hai. **Analogy:** Jaise kisi complex kaam ka \"Easy Button\" ya ek smart assistant.\n",
    "*   **Prompt:** Woh text jo hum AI model ko dete hain - jaise sawal, instruction ya request. **Analogy:** Jaise hum kisi dost ko message type karke baat karte hain.\n",
    "*   **Generated Text:** Woh text jo AI model hamare prompt ke jawab mein banata hai. **Analogy:** Hamare dost ka reply ya answer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Kya Seekha Aur Aage Kya? 🎉\n",
    "\n",
    "Waah! Aaj humne bahut kuch seekha:\n",
    "\n",
    "*   Humne samjha ki Language Models kya hote hain aur woh kaise computers ko hamari bhasha samajhne mein help karte hain.\n",
    "*   Humne dekha ki AI models ko tez chalane ke liye GPU power kitni zaroori hai.\n",
    "*   Humne seekha ki `transformers` library kya hai aur yeh AI models se dosti karne mein kaise help karti hai.\n",
    "*   Humne hamare pehle AI dost, Phi-3, ko load karna seekha - uske model aur tokenizer ke saath.\n",
    "*   Humne dekha ki `pipeline` kaise AI model ko use karna easy bana deta hai, jaise easy mode on karna.\n",
    "*   Humne samjha ki prompt kya hota hai aur hum kaise chat format mein AI model ko instruction dete hain.\n",
    "*   Aur finally, humne AI model se joke generate karwaya aur uska output dekha!\n",
    "\n",
    "Yeh sirf shuruat hai! Ab jab tumne seekh liya hai ki kaise ek basic Language Model load karke usse baat karte hain, tum aur explore kar sakte ho. Tum alag alag prompts try kar sakte ho - kahani likhwana, sawal poochhna, kisi topic par information lena.\n",
    "\n",
    "Aage chapters mein, tum aur bhi cool cheezein seekhoge ki Language Models kaise kaam karte hain, unko customize kaise karte hain aur unse aur bhi amazing chizein kaise karwate hain!\n",
    "\n",
    "Keep exploring the exciting world of Language AI! 🚀\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPCWg08aO4e8NWQuYCK5ppF",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
